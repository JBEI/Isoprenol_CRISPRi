{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f1bccf-0028-4c1a-aeb2-311728425d77",
   "metadata": {},
   "source": [
    "##### This requires the DBTL0_Top3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8076a360-bfdf-46bb-a515-8233b5474cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import re\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d94231-f798-42f1-826e-14240f736548",
   "metadata": {},
   "source": [
    "#### Import Top3 data of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366e01c-0d3e-4d95-a670-63fd37649570",
   "metadata": {},
   "source": [
    "Load Top3 data from each of the DBTL cycles for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed01ed3b-c668-4862-ac78-d3f44f322541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filenames and the samples of interest\n",
    "filenames = [f'DBTL{i}.csv' for i in range(7)]\n",
    "\n",
    "# Load CSV files and concatenate into a single dataframe\n",
    "dataframes = [pd.read_csv(filename) for filename in filenames]\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e80f3ddb-1e8b-41bc-bcca-aa840095ba59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein.Group</th>\n",
       "      <th>Protein.Names</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Protein.Description</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Replicate</th>\n",
       "      <th>Top_3pep_counts_mean</th>\n",
       "      <th>%_of protein_abundance_Top3-method</th>\n",
       "      <th>log10_%_abundance</th>\n",
       "      <th>Cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P00552</td>\n",
       "      <td>KKA2_KLEPN</td>\n",
       "      <td>Neo</td>\n",
       "      <td>Aminoglycoside 3'-phosphotransferase</td>\n",
       "      <td>Control</td>\n",
       "      <td>R1</td>\n",
       "      <td>119112382.0</td>\n",
       "      <td>3.112624</td>\n",
       "      <td>0.493127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P00552</td>\n",
       "      <td>KKA2_KLEPN</td>\n",
       "      <td>Neo</td>\n",
       "      <td>Aminoglycoside 3'-phosphotransferase</td>\n",
       "      <td>Control</td>\n",
       "      <td>R2</td>\n",
       "      <td>149172095.3</td>\n",
       "      <td>3.712705</td>\n",
       "      <td>0.569690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P00552</td>\n",
       "      <td>KKA2_KLEPN</td>\n",
       "      <td>Neo</td>\n",
       "      <td>Aminoglycoside 3'-phosphotransferase</td>\n",
       "      <td>Control</td>\n",
       "      <td>R3</td>\n",
       "      <td>138700868.7</td>\n",
       "      <td>3.700489</td>\n",
       "      <td>0.568259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P00552</td>\n",
       "      <td>KKA2_KLEPN</td>\n",
       "      <td>Neo</td>\n",
       "      <td>Aminoglycoside 3'-phosphotransferase</td>\n",
       "      <td>Control</td>\n",
       "      <td>R4</td>\n",
       "      <td>100306326.3</td>\n",
       "      <td>2.650788</td>\n",
       "      <td>0.423375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00552</td>\n",
       "      <td>KKA2_KLEPN</td>\n",
       "      <td>Neo</td>\n",
       "      <td>Aminoglycoside 3'-phosphotransferase</td>\n",
       "      <td>Control</td>\n",
       "      <td>R5</td>\n",
       "      <td>114276780.7</td>\n",
       "      <td>2.835433</td>\n",
       "      <td>0.452619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein.Group Protein.Names Protein                   Protein.Description  \\\n",
       "0        P00552    KKA2_KLEPN     Neo  Aminoglycoside 3'-phosphotransferase   \n",
       "1        P00552    KKA2_KLEPN     Neo  Aminoglycoside 3'-phosphotransferase   \n",
       "2        P00552    KKA2_KLEPN     Neo  Aminoglycoside 3'-phosphotransferase   \n",
       "3        P00552    KKA2_KLEPN     Neo  Aminoglycoside 3'-phosphotransferase   \n",
       "4        P00552    KKA2_KLEPN     Neo  Aminoglycoside 3'-phosphotransferase   \n",
       "\n",
       "    Sample Replicate  Top_3pep_counts_mean  \\\n",
       "0  Control        R1           119112382.0   \n",
       "1  Control        R2           149172095.3   \n",
       "2  Control        R3           138700868.7   \n",
       "3  Control        R4           100306326.3   \n",
       "4  Control        R5           114276780.7   \n",
       "\n",
       "   %_of protein_abundance_Top3-method  log10_%_abundance  Cycle  \n",
       "0                            3.112624           0.493127      0  \n",
       "1                            3.712705           0.569690      0  \n",
       "2                            3.700489           0.568259      0  \n",
       "3                            2.650788           0.423375      0  \n",
       "4                            2.835433           0.452619      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59c935-1914-4852-a4f8-f85875bce102",
   "metadata": {},
   "source": [
    "Translate Top3 proteins into locus identities and then transform all of the .csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0765e21c-f755-45d5-bad0-b323e511ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, N = 19710/2544333 proteins were not translated to locus names\n"
     ]
    }
   ],
   "source": [
    "# Load the name_df DataFrame for translation\n",
    "name_df = pd.read_csv('proteomics_id_translator_240305.csv') \n",
    "\n",
    "# Create a dictionary from the name_df for fast lookup\n",
    "translator_dict = pd.Series(name_df['locus'].values, index=name_df['extracted']).to_dict()\n",
    "\n",
    "# Use the dictionary to map the Protein.Group names to locus names\n",
    "combined_df['Protein.Group'] = combined_df['Protein.Group'].map(lambda x: translator_dict.get(x, x))\n",
    "\n",
    "# Count the number of non-translated protein groups\n",
    "nontranslated = combined_df['Protein.Group'].apply(lambda x: x not in translator_dict.values()).sum()\n",
    "print(f\"In total, N = {nontranslated}/{len(combined_df['Protein.Group'])} proteins were not translated to locus names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcc6f2-2f9a-47a1-82cb-09e7bcdaea1b",
   "metadata": {},
   "source": [
    "### Initialize a DataFrame to store log2 and log10 values for all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2bb75-547c-4b95-ab62-ef0135b9a56d",
   "metadata": {},
   "source": [
    "Include samples across all cycles to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66c53f2-2162-4202-a3ed-2c756d52690a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_of_interest = [\n",
    " # \"PP_0812_PP_0813_PP_0815\",\n",
    " # \"PP_0812_PP_0814_PP_0815\",\n",
    " # \"PP_0813_PP_0814_PP_0815\",\n",
    " # \"PP_0813_PP_0815\",\n",
    " # \"PP_0815\",\n",
    " # \"PP_0814_PP_0815\"]\n",
    "\n",
    "\"PP_0812_PP_0813\",\n",
    "\"PP_0812_PP_0814\",\n",
    "\"PP_0812_PP_0813_PP_0814\",\n",
    "\"PP_0813_PP_0814\",\n",
    "\"PP_0812\",\n",
    "\"PP_0813\",\n",
    "\"PP_0814\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db26f83-76d0-44bf-9ce2-d0febfe4ad00",
   "metadata": {},
   "source": [
    "Pairwise comparison of samples_of_interest to the controls pooled across all cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e881ec-1018-40d4-9eb4-0ccf1e5b2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store log2 and log10 results\n",
    "log2_log10_results = pd.DataFrame()\n",
    "sample_control_pairs = {sample: \"Control\" for sample in samples_of_interest}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f3025-2015-4f47-a671-2204156790ad",
   "metadata": {},
   "source": [
    "Log2_gold_change set to zero so that we can isolate any proteins with significant differnces compared to the control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f39059d-4c0d-41f3-94b9-f6e79a14c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for filtering\n",
    "log2_fold_change_threshold = 0\n",
    "p_value_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330e104a-c18e-4739-8846-360e3e1a24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicates_to_include = ['R4', 'R5', 'R6']\n",
    "# for sample, control in sample_control_pairs.items():\n",
    "#     # Filter data for the current sample and its control\n",
    "#     if sample in ['PP_0812', 'PP_0813']:\n",
    "#         sample_data = combined_df[(combined_df['Sample'] == sample) & (combined_df['Replicate'].isin(replicates_to_include))]\n",
    "#     else:\n",
    "#         sample_data = combined_df[combined_df['Sample'] == sample]\n",
    "    \n",
    "#     control_data = combined_df[combined_df['Sample'] == control]\n",
    "\n",
    "#     # Debug: Check if data is loaded correctly\n",
    "#     if sample_data.empty or control_data.empty:\n",
    "#         print(f\"No data for {sample} or {control}\")\n",
    "#         continue\n",
    "\n",
    "#     # Compute mean %_of protein_abundance_Top3-method for each protein\n",
    "#     sample_mean = sample_data.groupby('Protein.Group')['%_of protein_abundance_Top3-method'].mean().reset_index()\n",
    "#     control_mean = control_data.groupby('Protein.Group')['%_of protein_abundance_Top3-method'].mean().reset_index()\n",
    "\n",
    "#     # Rename columns for clarity\n",
    "#     sample_mean.rename(columns={'%_of protein_abundance_Top3-method': 'sample_abundance'}, inplace=True)\n",
    "#     control_mean.rename(columns={'%_of protein_abundance_Top3-method': 'control_abundance'}, inplace=True)\n",
    "\n",
    "#     # Merge the data on Protein.Group\n",
    "#     merged_data = pd.merge(sample_mean, control_mean, on='Protein.Group', how='outer')\n",
    "\n",
    "#     # Calculate log2 fold change (fill missing values with NaN)\n",
    "#     merged_data['log2_change'] = np.log2(merged_data['sample_abundance'] / merged_data['control_abundance'])\n",
    "\n",
    "#     # Debug: Check if log2_change contains NaN values\n",
    "#     if merged_data['log2_change'].isna().all():\n",
    "#         print(f\"All log2 fold changes are NaN for {sample} vs {control}\")\n",
    "#         continue\n",
    "\n",
    "#     # Compute p-values (assume replicates data exists for actual p-value calculation)\n",
    "#     sample_reps = sample_data[['Protein.Group', '%_of protein_abundance_Top3-method']]\n",
    "#     control_reps = control_data[['Protein.Group', '%_of protein_abundance_Top3-method']]\n",
    "\n",
    "#     p_values = []\n",
    "#     for protein in merged_data['Protein.Group']:\n",
    "#         group1 = sample_reps[sample_reps['Protein.Group'] == protein]['%_of protein_abundance_Top3-method']\n",
    "#         group2 = control_reps[control_reps['Protein.Group'] == protein]['%_of protein_abundance_Top3-method']\n",
    "#         if not group1.empty and not group2.empty:\n",
    "#             _, p_val = ttest_ind(group1, group2, equal_var=False)\n",
    "#         else:\n",
    "#             p_val = np.nan\n",
    "#         p_values.append(p_val)\n",
    "\n",
    "#     # Add p-values and log10 transformation\n",
    "#     merged_data['p_value'] = p_values\n",
    "#     merged_data['log10_p_value'] = -np.log10(merged_data['p_value'])\n",
    "\n",
    "#     # Debug: Check if log10_p_value contains NaN values\n",
    "#     if merged_data['log10_p_value'].isna().all():\n",
    "#         print(f\"All log10 p-values are NaN for {sample} vs {control}\")\n",
    "#         continue\n",
    "\n",
    "#     # Filter based on plotting criteria\n",
    "#     filtered_data = merged_data[\n",
    "#         (merged_data['log2_change'].abs() > log2_fold_change_threshold) &\n",
    "#         (merged_data['log10_p_value'] > -np.log10(p_value_threshold))\n",
    "#     ]\n",
    "\n",
    "#     # Store filtered results in log2_log10_results\n",
    "#     if log2_log10_results.empty:\n",
    "#         log2_log10_results = filtered_data[['Protein.Group', 'log2_change', 'log10_p_value']].copy()\n",
    "#         log2_log10_results.rename(\n",
    "#             columns={'log2_change': f'{sample}_log2_FC', 'log10_p_value': f'{sample}_log10_pval'},\n",
    "#             inplace=True\n",
    "#         )\n",
    "#     else:\n",
    "#         temp_results = filtered_data[['Protein.Group', 'log2_change', 'log10_p_value']].copy()\n",
    "#         temp_results.rename(\n",
    "#             columns={'log2_change': f'{sample}_log2_FC', 'log10_p_value': f'{sample}_log10_pval'},\n",
    "#             inplace=True\n",
    "#         )\n",
    "#         log2_log10_results = pd.merge(\n",
    "#             log2_log10_results,\n",
    "#             temp_results,\n",
    "#             left_on='Protein.Group',\n",
    "#             right_on='Protein.Group',\n",
    "#             how='outer'\n",
    "#         )\n",
    "\n",
    "# #     # Create volcano plot for the current sample\n",
    "# #     fold_change = merged_data['log2_change']\n",
    "# #     p_values = merged_data['log10_p_value']\n",
    "\n",
    "# #     plt.figure(figsize=(8, 6))\n",
    "# #     plt.scatter(fold_change, p_values, s=15, alpha=0.25)\n",
    "# #     plt.title(f\"{sample} vs {control}\")\n",
    "# #     plt.xlabel(\"Log2(Fold Change)\")\n",
    "# #     plt.ylabel(\"Log10(P-Value)\")\n",
    "# #     plt.grid(False)\n",
    "# #     plt.ylim(0,)\n",
    "# #     plt.xlim(-10, 10)\n",
    "\n",
    "# #     # Threshold lines\n",
    "# #     plt.axvline(x=log2_fold_change_threshold, color='r', linestyle='--', linewidth=1)\n",
    "# #     plt.axvline(x=-log2_fold_change_threshold, color='r', linestyle='--', linewidth=1)\n",
    "# #     plt.axhline(y=-np.log10(p_value_threshold), color='g', linestyle='--', linewidth=1)\n",
    "\n",
    "# #     # Annotate significant points; this adds arrows to each of the plots and is computationally intensive, will probably crash if threshold zero\n",
    "# # #     texts = []\n",
    "# # #     labels = merged_data['Protein.Group']\n",
    "# # #     for i, label in enumerate(labels):\n",
    "# # #         if (fold_change[i] > log2_fold_change_threshold or fold_change[i] <-log2_fold_change_threshold) and p_values[i] > -np.log10(p_value_threshold):\n",
    "# # #             text = plt.text(fold_change[i], p_values[i], label, fontsize=10)\n",
    "# # #             texts.append(text)\n",
    "\n",
    "# # #     if texts:\n",
    "# # #         adjust_text(texts, arrowprops=dict(arrowstyle='-', color='red', lw=1))\n",
    "\n",
    "# #     # Show the plot\n",
    "# #     # plt.show()\n",
    "\n",
    "# # Save the filtered log2 and log10 values to a CSV file\n",
    "# log2_log10_results.to_csv('No_Top3_Filter_log2_log10_values_by_significance.csv', index=False)\n",
    "# print(\"Filtered Log2 and Log10 values saved to 'filtered_log2_log10_values_by_significance.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000dadf-f940-4918-ab26-3796f71a6dd3",
   "metadata": {},
   "source": [
    "Filtered for %_of protein_abundance_Top3-method <0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff939bac-b86b-4011-89e0-595be7e58298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Log2 and Log10 values saved to 'Test.csv'\n"
     ]
    }
   ],
   "source": [
    "# DataFrames to store results\n",
    "log2_log10_results = pd.DataFrame()\n",
    "raw_abundance_results = pd.DataFrame()\n",
    "\n",
    "replicates_to_include = ['R4', 'R5', 'R6']\n",
    "for sample in sample_control_pairs.items():\n",
    "    # Filter data for the current sample and its control\n",
    "    if sample in ['PP_0812', 'PP_0813']:\n",
    "        sample_data = combined_df[(combined_df['Sample'] == sample) & (combined_df['Replicate'].isin(replicates_to_include))]\n",
    "    else:\n",
    "        sample_data = combined_df[combined_df['Sample'] == sample]\n",
    "    \n",
    "    control_data = combined_df[combined_df['Sample'] == control]\n",
    "\n",
    "    # Debug: Check if data is loaded correctly\n",
    "    if sample_data.empty or control_data.empty:\n",
    "        print(f\"No data for {sample} or {control}\")\n",
    "        continue\n",
    "\n",
    "    # Compute mean %_of protein_abundance_Top3-method for each protein\n",
    "    sample_mean = sample_data.groupby('Protein.Group')['%_of protein_abundance_Top3-method'].mean().reset_index()\n",
    "    control_mean = control_data.groupby('Protein.Group')['%_of protein_abundance_Top3-method'].mean().reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    sample_mean.rename(columns={'%_of protein_abundance_Top3-method': 'sample_abundance'}, inplace=True)\n",
    "    control_mean.rename(columns={'%_of protein_abundance_Top3-method': 'control_abundance'}, inplace=True)\n",
    "\n",
    "    # Filter sample_mean to include only abundances > 0.001\n",
    "    # sample_mean = sample_mean[sample_mean['sample_abundance'] > 0.001]\n",
    "    control_mean = control_mean[control_mean['control_abundance'] > 0.001]\n",
    "    # Merge the data on Protein.Group\n",
    "    merged_data = pd.merge(sample_mean, control_mean, on='Protein.Group', how='outer')\n",
    "\n",
    "    # Calculate log2 fold change (fill missing values with NaN)\n",
    "    merged_data['log2_change'] = np.log2(merged_data['sample_abundance'] / merged_data['control_abundance'])\n",
    "\n",
    "    # Debug: Check if log2_change contains NaN values\n",
    "    if merged_data['log2_change'].isna().all():\n",
    "        print(f\"All log2 fold changes are NaN for {sample} vs {control}\")\n",
    "        continue\n",
    "\n",
    "    # Compute p-values (assume replicates data exists for actual p-value calculation)\n",
    "    sample_reps = sample_data[['Protein.Group', '%_of protein_abundance_Top3-method']]\n",
    "    control_reps = control_data[['Protein.Group', '%_of protein_abundance_Top3-method']]\n",
    "\n",
    "    p_values = []\n",
    "    for protein in merged_data['Protein.Group']:\n",
    "        group1 = sample_reps[sample_reps['Protein.Group'] == protein]['%_of protein_abundance_Top3-method']\n",
    "        group2 = control_reps[control_reps['Protein.Group'] == protein]['%_of protein_abundance_Top3-method']\n",
    "        if not group1.empty and not group2.empty:\n",
    "            _, p_val = ttest_ind(group1, group2, equal_var=False)\n",
    "        else:\n",
    "            p_val = np.nan\n",
    "        p_values.append(p_val)\n",
    "\n",
    "    # Add p-values and log10 transformation\n",
    "    merged_data['p_value'] = p_values\n",
    "    merged_data['log10_p_value'] = -np.log10(merged_data['p_value'])\n",
    "\n",
    "    # Debug: Check if log10_p_value contains NaN values\n",
    "    if merged_data['log10_p_value'].isna().all():\n",
    "        print(f\"All log10 p-values are NaN for {sample} vs {control}\")\n",
    "        continue\n",
    "\n",
    "    # Filter based on plotting criteria\n",
    "    filtered_data = merged_data[\n",
    "        (merged_data['log2_change'].abs() > log2_fold_change_threshold) &\n",
    "        (merged_data['log10_p_value'] > -np.log10(p_value_threshold))\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Store filtered results in log2_log10_results\n",
    "    if log2_log10_results.empty:\n",
    "        log2_log10_results = filtered_data[['Protein.Group', 'log2_change', 'log10_p_value']].copy()\n",
    "        log2_log10_results.rename(\n",
    "            columns={'log2_change': f'{sample}_log2_FC', 'log10_p_value': f'{sample}_log10_pval'},\n",
    "            inplace=True\n",
    "        )\n",
    "    else:\n",
    "        temp_results = filtered_data[['Protein.Group', 'log2_change', 'log10_p_value']].copy()\n",
    "        temp_results.rename(\n",
    "            columns={'log2_change': f'{sample}_log2_FC', 'log10_p_value': f'{sample}_log10_pval'},\n",
    "            inplace=True\n",
    "        )\n",
    "        log2_log10_results = pd.merge(\n",
    "            log2_log10_results,\n",
    "            temp_results,\n",
    "            left_on='Protein.Group',\n",
    "            right_on='Protein.Group',\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "# Save the filtered log2 and log10 values to a CSV file\n",
    "log2_log10_results.to_csv('Test.csv', index=False)\n",
    "print(\"Filtered Log2 and Log10 values saved to 'Test.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd68e65-793b-4254-8bd0-94c3925a0a71",
   "metadata": {},
   "source": [
    "### Investigating genes that are upregulated amongst a subset of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b663e7-53d6-4bf3-8ee2-2fac9cfc7b57",
   "metadata": {},
   "source": [
    "#### TCA Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "745043c6-8034-476e-b051-6010afd85c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 out of 21 genes in the TCA cycle were significantly changed across strains\n",
      "Those genes were:\n",
      "Gene Accession Gene name                  Enzymatic activity  PP_0812_PP_0813_log2_FC  PP_0812_PP_0814_log2_FC  PP_0812_PP_0813_PP_0814_log2_FC  PP_0813_PP_0814_log2_FC  PP_0812_log2_FC  PP_0813_log2_FC  PP_0814_log2_FC  PP_0812_PP_0813_log10_pval  PP_0812_PP_0814_log10_pval  PP_0812_PP_0813_PP_0814_log10_pval  PP_0813_PP_0814_log10_pval  PP_0812_log10_pval  PP_0813_log10_pval  PP_0814_log10_pval\n",
      "       PP_4185      sucD             succinyl-CoA synthetase                -1.496664                -1.659155                        -1.500778                -1.178474        -1.191672        -1.173949        -1.186829                    3.264188                    5.467839                            3.184765                    5.737112            8.580141            2.400593           11.126186\n",
      "       PP_4186      sucC             succinyl-CoA synthetase                -1.634635                -1.187295                        -1.724108                -1.086489        -1.596163        -1.485355        -1.684811                   17.488664                    5.837821                           11.672409                    6.645970           17.549579            7.574928           16.889230\n",
      "       PP_4187      lpdG 2-oxoglutarate dehydrogenase system                -0.814749                -0.537811                        -0.755296                -0.550156        -0.720353        -0.526100        -0.788279                    8.797799                    5.691850                            8.328539                    3.115294            7.442227            6.081902            8.682425\n",
      "       PP_4189      sucA 2-oxoglutarate dehydrogenase system                -0.577684                -0.644560                        -0.728310                -0.580543        -0.661438        -0.551801        -0.773129                    7.074690                    2.138549                           11.973277                    2.058754            8.070072            2.414752            9.570732\n",
      "The genes were saved to 'locus_genes.csv'\n"
     ]
    }
   ],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-TCA.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "# Filter the data to include only the proteins that are significant for all samples of interest\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "\n",
    "# Compare the filtered data against the second list of proteins\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes in the TCA cycle were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "\n",
    "# Extract relevant columns\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84814d0-1814-46df-806d-14d4d24e4f2f",
   "metadata": {},
   "source": [
    "#### Branched Chain AA Superpathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261c9f9-df1e-4bb2-861b-a15ca3f5c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-BRANCHED-CHAIN-AA-SYN-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "\n",
    "# Compare the filtered data against the second list of proteins\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes in the AA superpathway were significantly changed across strains\")\n",
    "# Merge the matching proteins with the proteins_txt DataFrame to get additional information\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "\n",
    "# Extract relevant columns\n",
    "# Include columns for p-values and fold changes for the samples of interest\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda6918-c5dd-456c-9622-3393ae99fd82",
   "metadata": {},
   "source": [
    "#### Glycolysis Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85589d24-f0cf-4470-b622-e373219cfcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-PWY1G01-2.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "print(f\"{included} out of {total} genes in glycolysis were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37f622-8b36-49b3-8e0a-826ac0695928",
   "metadata": {},
   "source": [
    "#### Non-oxidative PP Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7062606-749d-49c4-a26c-ecb064eb7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-NONOXIPENT-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2000c7-0f96-4e44-9590-6948dcb33079",
   "metadata": {},
   "source": [
    "#### Oxidative PP Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae749b64-5fd1-4a2b-9280-c5ca4337cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-OXIDATIVEPENT-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38a3f4-a418-46df-973f-cf6b383e2b49",
   "metadata": {},
   "source": [
    "#### PP Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9fb01-e04d-4c5f-99fa-22e1d77d2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-PENTOSE-P-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4844bf-f0ca-4235-8c4f-b20d20d62e3f",
   "metadata": {},
   "source": [
    "#### Oxidative Phosphorylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13dd87-b3dd-4fb1-89be-bd2951710381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-PWY-Respiration_Pooled.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt2 = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt2['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8177627-4fa1-4f36-b3de-3496e5258903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('glutamine_glutamate.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt2 = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt2['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046bb54-3f39-4dec-9dbc-1997d5e2ba55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
