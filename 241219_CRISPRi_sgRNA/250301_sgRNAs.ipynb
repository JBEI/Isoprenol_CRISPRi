{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f1bccf-0028-4c1a-aeb2-311728425d77",
   "metadata": {},
   "source": [
    "##### This requires the DBTL0_Top3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8076a360-bfdf-46bb-a515-8233b5474cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import re\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d94231-f798-42f1-826e-14240f736548",
   "metadata": {},
   "source": [
    "#### Import Top3 data of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366e01c-0d3e-4d95-a670-63fd37649570",
   "metadata": {},
   "source": [
    "Load Top3 data from each of the DBTL cycles for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed01ed3b-c668-4862-ac78-d3f44f322541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filenames and the samples of interest\n",
    "filenames = [f'DBTL{i}.csv' for i in range(7)]\n",
    "\n",
    "# Load CSV files and concatenate into a single dataframe\n",
    "dataframes = [pd.read_csv(filename) for filename in filenames]\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59c935-1914-4852-a4f8-f85875bce102",
   "metadata": {},
   "source": [
    "Translate Top3 proteins into locus identities and then transform all of the .csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0765e21c-f755-45d5-bad0-b323e511ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, N = 19710/2544333 proteins were not translated to locus names\n"
     ]
    }
   ],
   "source": [
    "# Load the name_df DataFrame for translation\n",
    "name_df = pd.read_csv('proteomics_id_translator_240305.csv') \n",
    "\n",
    "# Create a dictionary from the name_df for fast lookup\n",
    "translator_dict = pd.Series(name_df['locus'].values, index=name_df['extracted']).to_dict()\n",
    "\n",
    "# Use the dictionary to map the Protein.Group names to locus names\n",
    "combined_df['Protein.Group'] = combined_df['Protein.Group'].map(lambda x: translator_dict.get(x, x))\n",
    "\n",
    "# Count the number of non-translated protein groups\n",
    "nontranslated = combined_df['Protein.Group'].apply(lambda x: x not in translator_dict.values()).sum()\n",
    "print(f\"In total, N = {nontranslated}/{len(combined_df['Protein.Group'])} proteins were not translated to locus names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcc6f2-2f9a-47a1-82cb-09e7bcdaea1b",
   "metadata": {},
   "source": [
    "### Initialize a DataFrame to store log2 and log10 values for all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2bb75-547c-4b95-ab62-ef0135b9a56d",
   "metadata": {},
   "source": [
    "Include samples across all cycles to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66c53f2-2162-4202-a3ed-2c756d52690a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_of_interest = [\n",
    "    \"PP_0368\",\n",
    "    \"PP_0437\",\n",
    "    \"PP_0528\",\n",
    "    \"PP_0812\",\n",
    "    \"PP_0813\",\n",
    "    \"PP_0814\",\n",
    "    \"PP_0815\",\n",
    "    \"PP_1317\",\n",
    "    \"PP_1506\",\n",
    "    \"PP_2136\",\n",
    "    \"PP_4120\",\n",
    "    \"PP_4189\",\n",
    "    \"PP_4191\",\n",
    "    \"PP_4192\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db26f83-76d0-44bf-9ce2-d0febfe4ad00",
   "metadata": {},
   "source": [
    "Pairwise comparison of samples_of_interest to the controls pooled across all cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e881ec-1018-40d4-9eb4-0ccf1e5b2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store log2 and log10 results\n",
    "log2_log10_results = pd.DataFrame()\n",
    "sample_control_pairs = {sample: \"Control\" for sample in samples_of_interest}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f3025-2015-4f47-a671-2204156790ad",
   "metadata": {},
   "source": [
    "Log2_gold_change set to zero so that we can isolate any proteins with significant differnces compared to the control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f39059d-4c0d-41f3-94b9-f6e79a14c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for filtering\n",
    "log2_fold_change_threshold = 0\n",
    "p_value_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcddfa34-514c-4862-9c66-49d0b5a76a41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "330e104a-c18e-4739-8846-360e3e1a24a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     sample_data \u001b[38;5;241m=\u001b[39m combined_df[(combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m sample) \u001b[38;5;241m&\u001b[39m (combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReplicate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(replicates_to_include))]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     sample_data \u001b[38;5;241m=\u001b[39m combined_df[\u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m sample]\n\u001b[0;32m      9\u001b[0m control_data \u001b[38;5;241m=\u001b[39m combined_df[combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m control]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Debug: Check if data is loaded correctly\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sample'"
     ]
    }
   ],
   "source": [
    "replicates_to_include = ['R4', 'R5', 'R6']\n",
    "for sample, control in sample_control_pairs.items():\n",
    "    # Filter data for the current sample and its control\n",
    "    if sample in ['PP_0812', 'PP_0813']:\n",
    "        sample_data = combined_df[(combined_df['Sample'] == sample) & (combined_df['Replicate'].isin(replicates_to_include))]\n",
    "    else:\n",
    "        sample_data = combined_df[combined_df['Sample'] == sample]\n",
    "    \n",
    "    control_data = combined_df[combined_df['Sample'] == control]\n",
    "\n",
    "    # Debug: Check if data is loaded correctly\n",
    "    if sample_data.empty or control_data.empty:\n",
    "        print(f\"No data for {sample} or {control}\")\n",
    "        continue\n",
    "\n",
    "    # Compute mean %_of protein_abundance_Top3-method for each protein\n",
    "    sample_mean = sample_data.groupby('Protein.Group')['%_of protein_abundance_Top3-method'].mean().reset_index()\n",
    "    control_mean = control_data.groupby('Protein.Group')['%_of protein_abundance_Top3-method'].mean().reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    sample_mean.rename(columns={'%_of protein_abundance_Top3-method': 'sample_abundance'}, inplace=True)\n",
    "    control_mean.rename(columns={'%_of protein_abundance_Top3-method': 'control_abundance'}, inplace=True)\n",
    "\n",
    "    # Merge the data on Protein.Group\n",
    "    merged_data = pd.merge(sample_mean, control_mean, on='Protein.Group', how='outer')\n",
    "\n",
    "    # Calculate log2 fold change (fill missing values with NaN)\n",
    "    merged_data['log2_change'] = np.log2(merged_data['sample_abundance'] / merged_data['control_abundance'])\n",
    "\n",
    "    # Debug: Check if log2_change contains NaN values\n",
    "    if merged_data['log2_change'].isna().all():\n",
    "        print(f\"All log2 fold changes are NaN for {sample} vs {control}\")\n",
    "        continue\n",
    "\n",
    "    # Compute p-values (assume replicates data exists for actual p-value calculation)\n",
    "    sample_reps = sample_data[['Protein.Group', '%_of protein_abundance_Top3-method']]\n",
    "    control_reps = control_data[['Protein.Group', '%_of protein_abundance_Top3-method']]\n",
    "\n",
    "    p_values = []\n",
    "    for protein in merged_data['Protein.Group']:\n",
    "        group1 = sample_reps[sample_reps['Protein.Group'] == protein]['%_of protein_abundance_Top3-method']\n",
    "        group2 = control_reps[control_reps['Protein.Group'] == protein]['%_of protein_abundance_Top3-method']\n",
    "        if not group1.empty and not group2.empty:\n",
    "            _, p_val = ttest_ind(group1, group2, equal_var=False)\n",
    "        else:\n",
    "            p_val = np.nan\n",
    "        p_values.append(p_val)\n",
    "\n",
    "    # Add p-values and log10 transformation\n",
    "    merged_data['p_value'] = p_values\n",
    "    merged_data['log10_p_value'] = -np.log10(merged_data['p_value'])\n",
    "\n",
    "    # Debug: Check if log10_p_value contains NaN values\n",
    "    if merged_data['log10_p_value'].isna().all():\n",
    "        print(f\"All log10 p-values are NaN for {sample} vs {control}\")\n",
    "        continue\n",
    "\n",
    "    # Filter based on plotting criteria\n",
    "    filtered_data = merged_data[\n",
    "        (merged_data['log2_change'].abs() > log2_fold_change_threshold) &\n",
    "        (merged_data['log10_p_value'] > -np.log10(p_value_threshold))\n",
    "    ]\n",
    "\n",
    "    # Store filtered results in log2_log10_results\n",
    "    if log2_log10_results.empty:\n",
    "        log2_log10_results = filtered_data[['Protein.Group', 'log2_change', 'log10_p_value']].copy()\n",
    "        log2_log10_results.rename(\n",
    "            columns={'log2_change': f'{sample}_log2_FC', 'log10_p_value': f'{sample}_log10_pval'},\n",
    "            inplace=True\n",
    "        )\n",
    "    else:\n",
    "        temp_results = filtered_data[['Protein.Group', 'log2_change', 'log10_p_value']].copy()\n",
    "        temp_results.rename(\n",
    "            columns={'log2_change': f'{sample}_log2_FC', 'log10_p_value': f'{sample}_log10_pval'},\n",
    "            inplace=True\n",
    "        )\n",
    "        log2_log10_results = pd.merge(\n",
    "            log2_log10_results,\n",
    "            temp_results,\n",
    "            left_on='Protein.Group',\n",
    "            right_on='Protein.Group',\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "#     # Create volcano plot for the current sample\n",
    "#     fold_change = merged_data['log2_change']\n",
    "#     p_values = merged_data['log10_p_value']\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.scatter(fold_change, p_values, s=15, alpha=0.25)\n",
    "#     plt.title(f\"{sample} vs {control}\")\n",
    "#     plt.xlabel(\"Log2(Fold Change)\")\n",
    "#     plt.ylabel(\"Log10(P-Value)\")\n",
    "#     plt.grid(False)\n",
    "#     plt.ylim(0,)\n",
    "#     plt.xlim(-10, 10)\n",
    "\n",
    "#     # Threshold lines\n",
    "#     plt.axvline(x=log2_fold_change_threshold, color='r', linestyle='--', linewidth=1)\n",
    "#     plt.axvline(x=-log2_fold_change_threshold, color='r', linestyle='--', linewidth=1)\n",
    "#     plt.axhline(y=-np.log10(p_value_threshold), color='g', linestyle='--', linewidth=1)\n",
    "\n",
    "#     # Annotate significant points; this adds arrows to each of the plots and is computationally intensive, will probably crash if threshold zero\n",
    "# #     texts = []\n",
    "# #     labels = merged_data['Protein.Group']\n",
    "# #     for i, label in enumerate(labels):\n",
    "# #         if (fold_change[i] > log2_fold_change_threshold or fold_change[i] <-log2_fold_change_threshold) and p_values[i] > -np.log10(p_value_threshold):\n",
    "# #             text = plt.text(fold_change[i], p_values[i], label, fontsize=10)\n",
    "# #             texts.append(text)\n",
    "\n",
    "# #     if texts:\n",
    "# #         adjust_text(texts, arrowprops=dict(arrowstyle='-', color='red', lw=1))\n",
    "\n",
    "#     # Show the plot\n",
    "#     # plt.show()\n",
    "\n",
    "# Save the filtered log2 and log10 values to a CSV file\n",
    "log2_log10_results.to_csv('Filtered_volcano_values.csv', index=False)\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000dadf-f940-4918-ab26-3796f71a6dd3",
   "metadata": {},
   "source": [
    "Filtered for %_of protein_abundance_Top3-method >0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd68e65-793b-4254-8bd0-94c3925a0a71",
   "metadata": {},
   "source": [
    "### Investigating genes that are upregulated amongst a subset of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b663e7-53d6-4bf3-8ee2-2fac9cfc7b57",
   "metadata": {},
   "source": [
    "#### TCA Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745043c6-8034-476e-b051-6010afd85c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-TCA.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "# Filter the data to include only the proteins that are significant for all samples of interest\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "\n",
    "# Compare the filtered data against the second list of proteins\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes in the TCA cycle were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "\n",
    "# Extract relevant columns\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84814d0-1814-46df-806d-14d4d24e4f2f",
   "metadata": {},
   "source": [
    "#### Branched Chain AA Superpathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261c9f9-df1e-4bb2-861b-a15ca3f5c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-BRANCHED-CHAIN-AA-SYN-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "\n",
    "# Compare the filtered data against the second list of proteins\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes in the AA superpathway were significantly changed across strains\")\n",
    "# Merge the matching proteins with the proteins_txt DataFrame to get additional information\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "\n",
    "# Extract relevant columns\n",
    "# Include columns for p-values and fold changes for the samples of interest\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda6918-c5dd-456c-9622-3393ae99fd82",
   "metadata": {},
   "source": [
    "#### Glycolysis Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85589d24-f0cf-4470-b622-e373219cfcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-PWY1G01-2.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "print(f\"{included} out of {total} genes in glycolysis were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37f622-8b36-49b3-8e0a-826ac0695928",
   "metadata": {},
   "source": [
    "#### Non-oxidative PP Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7062606-749d-49c4-a26c-ecb064eb7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-NONOXIPENT-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2000c7-0f96-4e44-9590-6948dcb33079",
   "metadata": {},
   "source": [
    "#### Oxidative PP Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae749b64-5fd1-4a2b-9280-c5ca4337cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-OXIDATIVEPENT-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38a3f4-a418-46df-973f-cf6b383e2b49",
   "metadata": {},
   "source": [
    "#### PP Pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9fb01-e04d-4c5f-99fa-22e1d77d2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-PENTOSE-P-PWY.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4844bf-f0ca-4235-8c4f-b20d20d62e3f",
   "metadata": {},
   "source": [
    "#### Oxidative Phosphorylation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13dd87-b3dd-4fb1-89be-bd2951710381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('pathway-genes-PWY-Respiration_Pooled.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt2 = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt2['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8177627-4fa1-4f36-b3de-3496e5258903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the second list of proteins\n",
    "proteins_txt = pd.read_csv('glutamine_glutamate.txt', delimiter='\\t')  # Adjust the separator if needed\n",
    "proteins_txt2 = proteins_txt.drop_duplicates(subset='Gene Accession')\n",
    "second_list = proteins_txt2['Gene Accession'].tolist()\n",
    "\n",
    "filtered_data = log2_log10_results.dropna(subset=[f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest])\n",
    "matching_proteins = filtered_data[filtered_data['Protein.Group'].isin(second_list)]\n",
    "matching_proteins.to_csv('matching_proteins.csv', index=False)\n",
    "# Calculate the ratio of significantly changed genes\n",
    "included = matching_proteins.shape[0]\n",
    "total = len(second_list)\n",
    "ratio = included / total\n",
    "\n",
    "print(f\"{included} out of {total} genes were significantly changed across strains\")\n",
    "merged_data = pd.merge(matching_proteins, proteins_txt, left_on='Protein.Group', right_on='Gene Accession')\n",
    "columns_to_include = ['Gene Accession', 'Gene name', 'Enzymatic activity'] + [f\"{sample}_log2_FC\" for sample in samples_of_interest] + [f\"{sample}_log10_pval\" for sample in samples_of_interest]\n",
    "locus_genes = merged_data[columns_to_include].drop_duplicates(subset='Gene Accession')\n",
    "\n",
    "# Print the genes by locus with additional information\n",
    "print(\"Those genes were:\")\n",
    "print(locus_genes.to_string(index=False))\n",
    "locus_genes.to_csv('locus_genes.csv', index=False)\n",
    "\n",
    "print(\"The genes were saved to 'locus_genes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046bb54-3f39-4dec-9dbc-1997d5e2ba55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
